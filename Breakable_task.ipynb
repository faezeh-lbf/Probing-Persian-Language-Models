{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breakable task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d86f91fee5d40c085ed1c9027f09be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d04b354db71e408e85838b977f69190b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eba15772935244f7ad9d365898a36338",
              "IPY_MODEL_4089910f5dc14f128c615b47ae6700cf",
              "IPY_MODEL_40c28ba2a15d46f2a7aed989db985ba4"
            ]
          }
        },
        "d04b354db71e408e85838b977f69190b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eba15772935244f7ad9d365898a36338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24538d81013d4c94b680bc7aa9fdf1fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70f6f952f07842348c3af55119052901"
          }
        },
        "4089910f5dc14f128c615b47ae6700cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae57c21c7341494ab94ef03aa1ba7d78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c59aae943db047348c46b92aa0ff73bf"
          }
        },
        "40c28ba2a15d46f2a7aed989db985ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c2289f166cc42f08d02cbcae49990e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ? tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d1a1e6619414557aae24c6c0d203f69"
          }
        },
        "24538d81013d4c94b680bc7aa9fdf1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70f6f952f07842348c3af55119052901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae57c21c7341494ab94ef03aa1ba7d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c59aae943db047348c46b92aa0ff73bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c2289f166cc42f08d02cbcae49990e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d1a1e6619414557aae24c6c0d203f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b13656e835fc4e988b187bbc32575536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ecd36948c89b4529b95ea362eaf2bdee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf64e77d9a414833b13806b5852fde91",
              "IPY_MODEL_c3bd30b3a36444a78dc2564e6557a31e",
              "IPY_MODEL_e9f94414b2154942870dd9ff5a306667"
            ]
          }
        },
        "ecd36948c89b4529b95ea362eaf2bdee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf64e77d9a414833b13806b5852fde91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_388dfddb263945d29a5f474304b4fe71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07b2afeba980456cac48c59f36ece86c"
          }
        },
        "c3bd30b3a36444a78dc2564e6557a31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca739405273b4b64a019e12311c31ec2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2224d76f350f4f7fa780530a23dfbfe9"
          }
        },
        "e9f94414b2154942870dd9ff5a306667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_387fdef1049341e2b81ffa823183116d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ? tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b494629226740d7810b3656d63c8d31"
          }
        },
        "388dfddb263945d29a5f474304b4fe71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07b2afeba980456cac48c59f36ece86c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca739405273b4b64a019e12311c31ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2224d76f350f4f7fa780530a23dfbfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "387fdef1049341e2b81ffa823183116d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b494629226740d7810b3656d63c8d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0558480fe44d40d2b466acaac649949b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1dde7bb4f44b46be80dc1fbc4e0178af",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cb74ff093a6405da9a85ee98fd420d5",
              "IPY_MODEL_e5a03545f6f64e97afbcd5cfae819a29",
              "IPY_MODEL_05e2bb590207488cb6afbae668904db5"
            ]
          }
        },
        "1dde7bb4f44b46be80dc1fbc4e0178af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cb74ff093a6405da9a85ee98fd420d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b0090ba44984ba8bcd37a8d5977103c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0389e32c79a54c2f97b37a0c64233620"
          }
        },
        "e5a03545f6f64e97afbcd5cfae819a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d844069a9e7456cba61bdd2d7f71a5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9b178bf06b849edad4d82392237ce59"
          }
        },
        "05e2bb590207488cb6afbae668904db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cf05151160e4db691e3b363161515ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:00&lt;00:00, 11.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7bf5191035b4190a2502b375f45446b"
          }
        },
        "3b0090ba44984ba8bcd37a8d5977103c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0389e32c79a54c2f97b37a0c64233620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d844069a9e7456cba61bdd2d7f71a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9b178bf06b849edad4d82392237ce59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cf05151160e4db691e3b363161515ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7bf5191035b4190a2502b375f45446b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ddbb4f311bf4928b2749a7a630fee94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c19ff2286a2e41e08d5fe13325e74797",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a91cb7d4ee7e4db7b2d2c0f45dd1cccd",
              "IPY_MODEL_bd60ccac666540feb47fe44b519f182a",
              "IPY_MODEL_4d6bd56e154447ae835a312e4223e6ea"
            ]
          }
        },
        "c19ff2286a2e41e08d5fe13325e74797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a91cb7d4ee7e4db7b2d2c0f45dd1cccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f20fac36c5543a3851a445cb18edb3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18a80cd46c4a4e1cbe9aba5821095662"
          }
        },
        "bd60ccac666540feb47fe44b519f182a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e0532fab6274f5aada431380f0dc0e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1215509,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1215509,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c9b32749d6840c1a774306960ca5d28"
          }
        },
        "4d6bd56e154447ae835a312e4223e6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_607e080b702e4080932a72b5990bc8f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.22M/1.22M [00:00&lt;00:00, 14.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_907b88437287414c9150b28ecbf0478e"
          }
        },
        "6f20fac36c5543a3851a445cb18edb3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18a80cd46c4a4e1cbe9aba5821095662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e0532fab6274f5aada431380f0dc0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c9b32749d6840c1a774306960ca5d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "607e080b702e4080932a72b5990bc8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "907b88437287414c9150b28ecbf0478e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c0460b0ec3243b39e1ae2984961bf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb0ff0de92e74f9c91903c4d4c21f451",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_860faba97d1c4ab8b016d2f41b6356c9",
              "IPY_MODEL_6b48b00ccad042c6aa31221b3559d6a1",
              "IPY_MODEL_465d711ca4244dd8a499931451ba25ac"
            ]
          }
        },
        "bb0ff0de92e74f9c91903c4d4c21f451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "860faba97d1c4ab8b016d2f41b6356c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2f9cccc05604ca38882806f8d9175ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d508c3133491469ea4e11b769ff8e473"
          }
        },
        "6b48b00ccad042c6aa31221b3559d6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d15fa8e03414a269a891a8f9366d328",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 654186735,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 654186735,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4570079875344bdebb52a8c277ac1cdd"
          }
        },
        "465d711ca4244dd8a499931451ba25ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ba150ef42ce465d999101ec7591061c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 654M/654M [00:16&lt;00:00, 53.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8bf18cd5f4f4941ae01ea5ede62c0c3"
          }
        },
        "d2f9cccc05604ca38882806f8d9175ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d508c3133491469ea4e11b769ff8e473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d15fa8e03414a269a891a8f9366d328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4570079875344bdebb52a8c277ac1cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ba150ef42ce465d999101ec7591061c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8bf18cd5f4f4941ae01ea5ede62c0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faezeh-lbf/Probing-Persian-Language-Models/blob/main/Breakable_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "source": [
        "! pip install git+https://github.com/huggingface/transformers.git\n",
        "! pip install git+https://github.com/huggingface/datasets.git\n",
        "from IPython.display import clear_output \n",
        "!pip install -q sentencepiece\n",
        "# !pip install ipywidgets\n",
        "# !pip install bertviz\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsbmJa6-gp0_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akdt-iyw6BJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e1d4d0-abd5-48f4-a012-0aab94abef3e"
      },
      "source": [
        "!pip install tqdm --upgrade\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.61.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAuE1zB5XfbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e385f1-ec3e-45b4-8f1d-c312757ebd11"
      },
      "source": [
        "from datasets import load_dataset, list_datasets, load_metric, load_dataset\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "batch_size = BATCH_SIZE\n",
        "# OPTIONS_ORDER = ['بزرگتر', 'کوچکتر']\n",
        "\n",
        "\n",
        "# size\n",
        "# datasets = load_dataset('json', data_files='/content/size_comp_train.jsonl').shuffle()\n",
        "# dataset_test = load_dataset('json', data_files='/content/size_comp_dev.jsonl').shuffle()\n",
        "datasets = load_dataset('json', data_files='/content/breakable_train2_nolang.jsonl').shuffle()\n",
        "dataset_test = load_dataset('json', data_files='/content/breakable_dev1.jsonl').shuffle()\n",
        "\n",
        "# # num\n",
        "# datasets = load_dataset('json', data_files='/content/ant-syn_train.jsonl').shuffle()\n",
        "# dataset_test = load_dataset('json', data_files='/content/ant-syn_dev.jsonl').shuffle()\n",
        "\n",
        "# age\n",
        "\n",
        "# datasets = load_dataset('json', data_files='/content/age_comp_train.jsonl').shuffle()\n",
        "# dataset_test = load_dataset('json', data_files='/content/age_comp_dev.jsonl').shuffle()\n",
        "\n",
        "datasets = datasets['train'].train_test_split(test_size=0.1)\n",
        "datasets['validation'] = datasets['test']\n",
        "datasets['test'] = dataset_test['train']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-063584867fd76e67\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264)\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264/cache-586b978c69010b25.arrow\n",
            "Using custom data configuration default-be3ea5e40df5363b\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-be3ea5e40df5363b/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264)\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/json/default-be3ea5e40df5363b/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264/cache-331690e607509901.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264/cache-761343d228ffcec6.arrow and /root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264/cache-4ac4445f2b9e7bfe.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chdD8oMPoTFR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "8d86f91fee5d40c085ed1c9027f09be6",
            "d04b354db71e408e85838b977f69190b",
            "eba15772935244f7ad9d365898a36338",
            "4089910f5dc14f128c615b47ae6700cf",
            "40c28ba2a15d46f2a7aed989db985ba4",
            "24538d81013d4c94b680bc7aa9fdf1fe",
            "70f6f952f07842348c3af55119052901",
            "ae57c21c7341494ab94ef03aa1ba7d78",
            "c59aae943db047348c46b92aa0ff73bf",
            "8c2289f166cc42f08d02cbcae49990e1",
            "6d1a1e6619414557aae24c6c0d203f69",
            "b13656e835fc4e988b187bbc32575536",
            "ecd36948c89b4529b95ea362eaf2bdee",
            "cf64e77d9a414833b13806b5852fde91",
            "c3bd30b3a36444a78dc2564e6557a31e",
            "e9f94414b2154942870dd9ff5a306667",
            "388dfddb263945d29a5f474304b4fe71",
            "07b2afeba980456cac48c59f36ece86c",
            "ca739405273b4b64a019e12311c31ec2",
            "2224d76f350f4f7fa780530a23dfbfe9",
            "387fdef1049341e2b81ffa823183116d",
            "7b494629226740d7810b3656d63c8d31"
          ]
        },
        "outputId": "2d310327-b2d6-473f-9377-0d8afb40641b"
      },
      "source": [
        "# nolang datasets\n",
        "from datasets import load_dataset, list_datasets, load_metric, load_dataset\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "batch_size = BATCH_SIZE\n",
        "# OPTIONS_ORDER = ['بزرگتر', 'کوچکتر']\n",
        "\n",
        "\n",
        "# size\n",
        "# nolang_datasets = load_dataset('json', data_files='/content/nolang_size_comp_train.jsonl').shuffle()\n",
        "# nolang_dataset_test = load_dataset('json', data_files='/content/nolang_size_comp_dev.jsonl').shuffle()\n",
        "nolang_datasets = load_dataset('json', data_files='/content/breakable_train2_nolang.jsonl').shuffle()\n",
        "nolang_dataset_test = load_dataset('json', data_files='/content/breakable_dev1_nolang.jsonl').shuffle()\n",
        "\n",
        "# # num\n",
        "# datasets = load_dataset('json', data_files='/content/ant-syn_train.jsonl').shuffle()\n",
        "# dataset_test = load_dataset('json', data_files='/content/ant-syn_dev.jsonl').shuffle()\n",
        "\n",
        "# age\n",
        "# datasets = load_dataset('json', data_files='/content/age_comp_train.jsonl').shuffle()\n",
        "# dataset_test = load_dataset('json', data_files='/content/age_comp_dev.jsonl').shuffle()\n",
        "\n",
        "nolang_datasets = nolang_datasets['train'].train_test_split(test_size=0.1)\n",
        "nolang_datasets['validation'] = nolang_datasets['test']\n",
        "nolang_datasets['test'] = nolang_dataset_test['train']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-063584867fd76e67\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d86f91fee5d40c085ed1c9027f09be6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-532445b518491a1a\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.\n",
            "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-532445b518491a1a/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b13656e835fc4e988b187bbc32575536",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-532445b518491a1a/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuQIPUyaKDoE"
      },
      "source": [
        "nolang_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o1D5GA7w1fB"
      },
      "source": [
        "# Common"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhZw4_xR0GmZ"
      },
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVvslsfMIrIh"
      },
      "source": [
        "\n",
        "# @title model checkpoints\n",
        "# eng_model_checkpoint = \"bert-base-uncased\"\n",
        "model_checkpoint = \"HooshvareLab/bert-base-parsbert-uncased\"\n",
        "# model_checkpoint = \"HooshvareLab/albert-fa-zwnj-base-v2\"\n",
        "# model_checkpoint = 'bert-base-multilingual-cased'\n",
        "# model_checkpoint = 'HooshvareLab/roberta-fa-zwnj-base'\n",
        "\n",
        "# roberta-fa-zwnj-base\n",
        "# TODO: change Model to persian one\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BGR6FD4qyUQ"
      },
      "source": [
        "# @title learning curve functions\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "import random\n",
        "import numpy as np\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "\n",
        "def create_dataloader(dataset, batch_size=BATCH_SIZE):\n",
        "  dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler( dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "  return dataloader\n",
        "\n",
        "def prepare_model(model_class, model_checkpoint):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "  base_model = AutoModelForMaskedLM.from_pretrained(model_checkpoint, return_dict = True)\n",
        "  \n",
        "  model = model_class(base_model, tokenizer)\n",
        "  model.cuda()\n",
        "  return model\n",
        "\n",
        "  \n",
        "\n",
        "def learning_curve(model_class, model_checkpoint, datasets, learning_sizes = [64, 128, 256, 512, 1024, 2048], batch_size=BATCH_SIZE):\n",
        "  train_dataset = datasets['train']\n",
        "  val_dataset = datasets['validation']\n",
        "  val_dataset = prepare_dataset(val_dataset)\n",
        "\n",
        "  validation_dataloader = create_dataloader(val_dataset, batch_size)\n",
        "  test_dataloader = create_dataloader(prepare_dataset(datasets['test']), batch_size)\n",
        "\n",
        "  results = {}\n",
        "\n",
        "  for c in learning_sizes:\n",
        "    if len(datasets['train']) > c:\n",
        "      train_dataset2 = prepare_dataset(train_dataset, c)\n",
        "      train_dataloader = create_dataloader(train_dataset2, batch_size)\n",
        "      model = prepare_model(model_class, model_checkpoint)\n",
        "      train_model(model, train_dataloader, validation_dataloader)\n",
        "      eval_result = evaluate_model(model, test_dataloader)\n",
        "      results[c] = eval_result\n",
        "    else:\n",
        "      c = len(datasets['train'])\n",
        "      train_dataset2 = prepare_dataset(train_dataset, c)\n",
        "      train_dataloader = create_dataloader(train_dataset2, batch_size)\n",
        "      model = model_class()\n",
        "      train_model(model, train_dataloader, validation_dataloader)\n",
        "      eval_result = evaluate_model(model, test_dataloader)\n",
        "      results[c] = evel_result\n",
        "      return results\n",
        "  return results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exsWYMSyVbgy"
      },
      "source": [
        "# @title fix label\n",
        "\n",
        "def fix_labels(ex):\n",
        "  c=ex['question']['choices']\n",
        "  options = []\n",
        "  for i in c:\n",
        "    options.append(i['text'])\n",
        "  options = [tokenizer.encode(option)[1] for option in options]\n",
        "  ex['fixed_label']=ex['label']\n",
        "  # print(options)\n",
        "  ex['options'] = torch.tensor(options)\n",
        "  ex['question']['stem']=ex['question']['stem'].replace('[MASK]',tokenizer.mask_token)\n",
        "  enc=tokenizer.encode_plus(ex['question']['stem'],truncation=True,padding='max_length', max_length=64)\n",
        "  ex={**ex,**enc}\n",
        "  sol = {}\n",
        "  cols = ['input_ids', 'attention_mask', 'fixed_label', 'options']\n",
        "  for k in ex:\n",
        "    if k in cols:\n",
        "      sol[k] = ex[k]\n",
        "  return sol\n",
        "\n",
        "def prepare_dataset(dataset, data_size = -1):\n",
        "  if data_size != -1:\n",
        "    dataset = dataset.train_test_split(data_size, seed = np.random.randint(1000))['test']\n",
        "  encoded_dataset = dataset.map(fix_labels)\n",
        "  # print(encoded_dataset[0])\n",
        "  # raise 1\n",
        "  encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'fixed_label', 'options'])\n",
        "  return encoded_dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2whpts9JoEw"
      },
      "source": [
        "# testset = datasets['test']\n",
        "# testset = prepare_dataset(testset)\n",
        "# print(testset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1PA9KskwHwn",
        "cellView": "form"
      },
      "source": [
        "# @title train_model function\n",
        "\n",
        "# def train_model(model, train_dataloader, validation_dataloader):\n",
        "\n",
        "#   # Set the seed value all over the place to make this reproducible.\n",
        "#   seed_val = 42\n",
        "\n",
        "#   random.seed(seed_val)\n",
        "#   np.random.seed(seed_val)\n",
        "#   torch.manual_seed(seed_val)\n",
        "#   torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "#   # We'll store a number of quantities such as training and validation loss, \n",
        "#   # validation accuracy, and timings.\n",
        "#   training_stats = []\n",
        "\n",
        "#   # Measure the total training time for the whole run.\n",
        "#   total_t0 = time.time()\n",
        "\n",
        "#   optimizer = AdamW(model.parameters(),\n",
        "#                     lr = 2e-3, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "#                     eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "#                   )\n",
        "#   total_steps = len(train_dataloader) * epochs\n",
        "#   scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "#                                               num_warmup_steps = 0, # Default value in run_glue.py\n",
        "#                                               num_training_steps = total_steps)\n",
        "#   criterion = torch.nn.CrossEntropyLoss() \n",
        "\n",
        "#   # For each epoch...\n",
        "#   for epoch_i in range(0, epochs):\n",
        "      \n",
        "#       # ========================================\n",
        "#       #               Training\n",
        "#       # ========================================\n",
        "      \n",
        "#       # Perform one full pass over the training set.\n",
        "\n",
        "#       print(\"\")\n",
        "#       print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "#       print('Training...')\n",
        "\n",
        "#       # Measure how long the training epoch takes.\n",
        "#       t0 = time.time()\n",
        "\n",
        "#       # Reset the total loss for this epoch.\n",
        "#       total_train_loss = 0\n",
        "\n",
        "#       # Put the model into training mode. Don't be mislead--the call to \n",
        "#       # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "#       # `dropout` and `batchnorm` layers behave differently during training\n",
        "#       # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "#       model.train()\n",
        "\n",
        "#       # For each batch of training data...\n",
        "#       for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "#           # Progress update every 40 batches.\n",
        "#           if step % 40 == 0 and not step == 0:\n",
        "#               # Calculate elapsed time in minutes.\n",
        "#               elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "#               # Report progress.\n",
        "#               print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "#           # Unpack this training batch from our dataloader. \n",
        "#           #\n",
        "#           # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "#           # `to` method.\n",
        "#           #\n",
        "#           # `batch` contains three pytorch tensors:\n",
        "#           #   [0]: input ids \n",
        "#           #   [1]: attention masks\n",
        "#           #   [2]: labels \n",
        "\n",
        "#           b_input_ids =batch['input_ids'].to(device)\n",
        "#           # print(b_input_ids)\n",
        "#           b_input_mask = batch['attention_mask'].to(device)\n",
        "#           # # token_type_ids = torch.stack(batch['token_type_ids']).to(device)\n",
        "#           b_labels = batch['fixed_label'].to(device)\n",
        "\n",
        "#           # Always clear any previously calculated gradients before performing a\n",
        "#           # backward pass. PyTorch doesn't do this automatically because \n",
        "#           # accumulating the gradients is \"convenient while training RNNs\". \n",
        "#           # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "#           model.zero_grad()        \n",
        "\n",
        "#           # Perform a forward pass (evaluate the model on this training batch).\n",
        "#           # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "#           # function and pass down the arguments. The `forward` function is \n",
        "#           # documented here: \n",
        "#           # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "#           # The results are returned in a results object, documented here:\n",
        "#           # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "#           # Specifically, we'll get the loss (because we provided labels) and the\n",
        "#           # \"logits\"--the model outputs prior to activation.\n",
        "#           # print(b_input_ids.shape,b_labels.shape,b_input_mask.shape)\n",
        "#           result = model(ids=b_input_ids, \n",
        "#                         mask=b_input_mask, \n",
        "#                         labels=b_labels) \n",
        "#           loss = criterion(result, b_labels)\n",
        "#           # print(loss)\n",
        "#           # loss = result.loss\n",
        "#           # logits = result.logits\n",
        "#           # print('-----------------loss------------')\n",
        "#           # print(loss)\n",
        "\n",
        "#           # Accumulate the training loss over all of the batches so that we can\n",
        "#           # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "#           # single value; the `.item()` function just returns the Python value \n",
        "#           # from the tensor.\n",
        "#           total_train_loss += loss.item()\n",
        "\n",
        "#           # Perform a backward pass to calculate the gradients.\n",
        "#           # loss.requires_grad = True\n",
        "#           loss.backward()\n",
        "\n",
        "#           # Clip the norm of the gradients to 1.0.\n",
        "#           # This is to help prevent the \"exploding gradients\" problem.\n",
        "#           torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "#           # Update parameters and take a step using the computed gradient.\n",
        "#           # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "#           # modified based on their gradients, the learning rate, etc.\n",
        "#           optimizer.step()\n",
        "\n",
        "#           # Update the learning rate.\n",
        "#           scheduler.step()\n",
        "\n",
        "#       # Calculate the average loss over all of the batches.\n",
        "#       avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "      \n",
        "#       # Measure how long this epoch took.\n",
        "#       training_time = format_time(time.time() - t0)\n",
        "\n",
        "#       print(\"\")\n",
        "#       print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "#       print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "          \n",
        "#       # ========================================\n",
        "#       #               Validation\n",
        "#       # ========================================\n",
        "#       # After the completion of each training epoch, measure our performance on\n",
        "#       # our validation set.\n",
        "\n",
        "#       print(\"\")\n",
        "#       print(\"Running Validation...\")\n",
        "\n",
        "#       t0 = time.time()\n",
        "\n",
        "#       # Put the model in evaluation mode--the dropout layers behave differently\n",
        "#       # during evaluation.\n",
        "#       model.eval()\n",
        "      \n",
        "#       # Tracking variables \n",
        "#       total_eval_accuracy = 0\n",
        "#       total_eval_loss = 0\n",
        "#       nb_eval_steps = 0\n",
        "\n",
        "#       # Evaluate data for one epoch\n",
        "#       for batch in validation_dataloader:\n",
        "          \n",
        "#           # Unpack this training batch from our dataloader. \n",
        "#           #\n",
        "#           # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "#           # the `to` method.\n",
        "#           #\n",
        "#           # `batch` contains three pytorch tensors:\n",
        "#           #   [0]: input ids \n",
        "#           #   [1]: attention masks\n",
        "#           #   [2]: labels \n",
        "#           # print(batch)\n",
        "#           b_input_ids = batch['input_ids'].to(device)\n",
        "#           b_input_mask = batch['attention_mask'].to(device)\n",
        "#           b_labels = batch['fixed_label'].to(device)\n",
        "          \n",
        "#           # Tell pytorch not to bother with constructing the compute graph during\n",
        "#           # the forward pass, since this is only needed for backprop (training).\n",
        "#           with torch.no_grad():        \n",
        "\n",
        "#               # Forward pass, calculate logit predictions.\n",
        "#               # token_type_ids is the same as the \"segment ids\", which \n",
        "#               # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "#               result = model(ids=b_input_ids, \n",
        "#                         mask=b_input_mask, \n",
        "#                         labels=b_labels)\n",
        "\n",
        "#           # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "#           # output values prior to applying an activation function like the \n",
        "#           # softmax.\n",
        "#           loss = criterion(result, b_labels)\n",
        "              \n",
        "#           # Accumulate the validation loss.\n",
        "#           total_eval_loss += loss.item()\n",
        "\n",
        "#           # Move logits and labels to CPU\n",
        "#           logits = result.detach().cpu().numpy()\n",
        "#           label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "#           # Calculate the accuracy for this batch of test sentences, and\n",
        "#           # accumulate it over all batches.\n",
        "#           total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "          \n",
        "\n",
        "#       # Report the final accuracy for this validation run.\n",
        "#       avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "#       print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "#       # Calculate the average loss over all of the batches.\n",
        "#       avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "      \n",
        "#       # Measure how long the validation run took.\n",
        "#       validation_time = format_time(time.time() - t0)\n",
        "      \n",
        "#       print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "#       print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "#       # Record all statistics from this epoch.\n",
        "#       training_stats.append(\n",
        "#           {\n",
        "#               'epoch': epoch_i + 1,\n",
        "#               'Training Loss': avg_train_loss,\n",
        "#               'Valid. Loss': avg_val_loss,\n",
        "#               'Valid. Accur.': avg_val_accuracy,\n",
        "#               'Training Time': training_time,\n",
        "#               'Validation Time': validation_time\n",
        "#           }\n",
        "#       )\n",
        "\n",
        "#   print(\"\")\n",
        "#   print(\"Training complete!\")\n",
        "\n",
        "#   print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "#   return avg_val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u-adU6OGcmM",
        "cellView": "form"
      },
      "source": [
        "#  @title evaluate_model function\n",
        "\n",
        "# def evaluate_model(model, test_dataloader):\n",
        "#   model.eval()\n",
        "\n",
        "#   # Tracking variables \n",
        "#   total_eval_accuracy = 0\n",
        "#   total_eval_loss = 0\n",
        "#   # Evaluate data for one epoch\n",
        "#   for batch in test_dataloader:\n",
        "\n",
        "#       b_input_ids = batch['input_ids'].to(device)\n",
        "#       b_input_mask = batch['attention_mask'].to(device)\n",
        "#       b_labels = batch['fixed_label'].to(device)\n",
        "#       with torch.no_grad():\n",
        "#         result = model(ids=b_input_ids, \n",
        "#                       mask=b_input_mask, \n",
        "#                       labels=b_labels)\n",
        "\n",
        "#       # Move logits and labels to CPU\n",
        "#       logits = result.detach().cpu().numpy()\n",
        "#       label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "#       # Calculate the accuracy for this batch of test sentences, and\n",
        "#       # accumulate it over all batches.\n",
        "#       total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "      \n",
        "\n",
        "#   # Report the final accuracy for this validation run.\n",
        "#   avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "#   print(\"  Accuracy on test set: {0:.2f}\".format(avg_val_accuracy))\n",
        "#   return avg_val_accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1WOLmD8q_tR"
      },
      "source": [
        "# @title train_model function - real\n",
        "\n",
        "def train_model(model, train_dataloader, validation_dataloader):\n",
        "  print(\"=======================================================================\")\n",
        "  seed_val = 42\n",
        "\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "  # We'll store a number of quantities such as training and validation loss, \n",
        "  # validation accuracy, and timings.\n",
        "  training_stats = []\n",
        "\n",
        "  # Measure the total training time for the whole run.\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                              num_training_steps = total_steps)\n",
        "  criterion = torch.nn.CrossEntropyLoss() \n",
        "\n",
        "  # For each epoch...\n",
        "  for epoch_i in range(0, epochs):\n",
        "      \n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "      \n",
        "      # Perform one full pass over the training set.\n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      # Measure how long the training epoch takes.\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Reset the total loss for this epoch.\n",
        "      total_train_loss = 0\n",
        "\n",
        "      # Put the model into training mode. Don't be mislead--the call to \n",
        "      # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "      # `dropout` and `batchnorm` layers behave differently during training\n",
        "      # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "      model.train()\n",
        "\n",
        "      # For each batch of training data...\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "          # Progress update every 40 batches.\n",
        "          if step % 40 == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Report progress.\n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "          # `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "\n",
        "          b_input_ids =batch['input_ids'].to(device)\n",
        "          # print(b_input_ids)\n",
        "          b_input_mask = batch['attention_mask'].to(device)\n",
        "          # # token_type_ids = torch.stack(batch['token_type_ids']).to(device)\n",
        "          b_labels = batch['fixed_label'].to(device)\n",
        "          b_options = batch['options'].to(device)\n",
        "\n",
        "          # Always clear any previously calculated gradients before performing a\n",
        "          # backward pass. PyTorch doesn't do this automatically because \n",
        "          # accumulating the gradients is \"convenient while training RNNs\". \n",
        "          # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "          model.zero_grad()        \n",
        "\n",
        "          # Perform a forward pass (evaluate the model on this training batch).\n",
        "          # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "          # function and pass down the arguments. The `forward` function is \n",
        "          # documented here: \n",
        "          # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "          # The results are returned in a results object, documented here:\n",
        "          # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "          # Specifically, we'll get the loss (because we provided labels) and the\n",
        "          # \"logits\"--the model outputs prior to activation.\n",
        "          # print(b_input_ids.shape,b_labels.shape,b_input_mask.shape)\n",
        "          result = model(ids=b_input_ids, \n",
        "                        mask=b_input_mask, \n",
        "                        labels=b_labels,\n",
        "                        options = b_options) \n",
        "          \n",
        "          loss = criterion(result, b_labels)\n",
        "          # print(loss)\n",
        "          # loss = result.loss\n",
        "          # logits = result.logits\n",
        "          # print('-----------------loss------------')\n",
        "          # print(loss)\n",
        "\n",
        "          # Accumulate the training loss over all of the batches so that we can\n",
        "          # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "          # single value; the `.item()` function just returns the Python value \n",
        "          # from the tensor.\n",
        "          # print(loss.item())\n",
        "          total_train_loss += loss.item()\n",
        "\n",
        "\n",
        "          # Perform a backward pass to calculate the gradients.\n",
        "          # print(loss.requires_grad)\n",
        "          # loss.requires_grad = True\n",
        "          # loss = Variable(loss, requires_grad = True)\n",
        "          loss.backward()\n",
        "\n",
        "          # Clip the norm of the gradients to 1.0.\n",
        "          # This is to help prevent the \"exploding gradients\" problem.\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "          # Update parameters and take a step using the computed gradient.\n",
        "          # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "          # modified based on their gradients, the learning rate, etc.\n",
        "          # raise 1\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          # Update the learning rate.\n",
        "          scheduler.step()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "      \n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "      # for p in params[0:5]:\n",
        "      #     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "      # par = list(model.named_parameters())\n",
        "      # params.append(par)\n",
        "      # print(params[-4])\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "          \n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "      # After the completion of each training epoch, measure our performance on\n",
        "      # our validation set.\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Put the model in evaluation mode--the dropout layers behave differently\n",
        "      # during evaluation.\n",
        "      model.eval()\n",
        "      \n",
        "      # Tracking variables \n",
        "      total_eval_accuracy = 0\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "\n",
        "      # Evaluate data for one epoch\n",
        "      for batch in validation_dataloader:\n",
        "          \n",
        "          # Unpack this training batch from our dataloader. \n",
        "          #\n",
        "          # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "          # the `to` method.\n",
        "          #\n",
        "          # `batch` contains three pytorch tensors:\n",
        "          #   [0]: input ids \n",
        "          #   [1]: attention masks\n",
        "          #   [2]: labels \n",
        "          # print(batch)\n",
        "          b_input_ids = batch['input_ids'].to(device)\n",
        "          b_input_mask = batch['attention_mask'].to(device)\n",
        "          b_labels = batch['fixed_label'].to(device)\n",
        "          b_options = batch['options'].to(device)\n",
        "          \n",
        "          # Tell pytorch not to bother with constructing the compute graph during\n",
        "          # the forward pass, since this is only needed for backprop (training).\n",
        "          with torch.no_grad():        \n",
        "\n",
        "              # Forward pass, calculate logit predictions.\n",
        "              # token_type_ids is the same as the \"segment ids\", which \n",
        "              # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "              result = model(ids=b_input_ids, \n",
        "                        mask=b_input_mask, \n",
        "                        labels=b_labels,\n",
        "                        options = b_options)\n",
        "\n",
        "          # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "          # output values prior to applying an activation function like the \n",
        "          # softmax.\n",
        "          loss = criterion(result, b_labels)\n",
        "              \n",
        "          # Accumulate the validation loss.\n",
        "          total_eval_loss += loss.item()\n",
        "\n",
        "          # Move logits and labels to CPU\n",
        "          logits = result.detach().cpu().numpy()\n",
        "          label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "          # Calculate the accuracy for this batch of test sentences, and\n",
        "          # accumulate it over all batches.\n",
        "          total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "          \n",
        "\n",
        "      # Report the final accuracy for this validation run.\n",
        "      avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "      print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "      \n",
        "      # Measure how long the validation run took.\n",
        "      validation_time = format_time(time.time() - t0)\n",
        "      \n",
        "      print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "      print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "      # Record all statistics from this epoch.\n",
        "      training_stats.append(\n",
        "          {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Valid. Accur.': avg_val_accuracy,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "  return avg_val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57E_IxWpq_tS"
      },
      "source": [
        "#  @title evaluate_model function\n",
        "\n",
        "def evaluate_model(model, test_dataloader):\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in test_dataloader:\n",
        "\n",
        "      b_input_ids = batch['input_ids'].to(device)\n",
        "      b_input_mask = batch['attention_mask'].to(device)\n",
        "      b_labels = batch['fixed_label'].to(device)\n",
        "      b_options= batch['options'].to(device)\n",
        "      with torch.no_grad():\n",
        "        result = model(ids=b_input_ids, \n",
        "                      mask=b_input_mask, \n",
        "                      labels=b_labels,\n",
        "                      options=b_options)\n",
        "\n",
        "      # Move logits and labels to CPU\n",
        "      logits = result.detach().cpu().numpy()\n",
        "      label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "      # Calculate the accuracy for this batch of test sentences, and\n",
        "      # accumulate it over all batches.\n",
        "      total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "      \n",
        "\n",
        "  # Report the final accuracy for this validation run.\n",
        "  avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "  print(\"  Accuracy on test set: {0:.2f}\".format(avg_val_accuracy))\n",
        "  return avg_val_accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92-JaGmXkejT"
      },
      "source": [
        "## curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iTjtZIY4iXM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0558480fe44d40d2b466acaac649949b",
            "1dde7bb4f44b46be80dc1fbc4e0178af",
            "9cb74ff093a6405da9a85ee98fd420d5",
            "e5a03545f6f64e97afbcd5cfae819a29",
            "05e2bb590207488cb6afbae668904db5",
            "3b0090ba44984ba8bcd37a8d5977103c",
            "0389e32c79a54c2f97b37a0c64233620",
            "3d844069a9e7456cba61bdd2d7f71a5e",
            "c9b178bf06b849edad4d82392237ce59",
            "3cf05151160e4db691e3b363161515ac",
            "c7bf5191035b4190a2502b375f45446b",
            "0ddbb4f311bf4928b2749a7a630fee94",
            "c19ff2286a2e41e08d5fe13325e74797",
            "a91cb7d4ee7e4db7b2d2c0f45dd1cccd",
            "bd60ccac666540feb47fe44b519f182a",
            "4d6bd56e154447ae835a312e4223e6ea",
            "6f20fac36c5543a3851a445cb18edb3a",
            "18a80cd46c4a4e1cbe9aba5821095662",
            "0e0532fab6274f5aada431380f0dc0e0",
            "7c9b32749d6840c1a774306960ca5d28",
            "607e080b702e4080932a72b5990bc8f6",
            "907b88437287414c9150b28ecbf0478e"
          ]
        },
        "outputId": "29a10bd1-bb28-4035-da19-f088b06131f0"
      },
      "source": [
        "import torch\n",
        "epochs=3\n",
        "device = torch.device(\"cuda\")\n",
        "# model_checkpoint = 'HooshvareLab/roberta-fa-zwnj-base'\n",
        "model_checkpoint = \"HooshvareLab/bert-base-parsbert-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0558480fe44d40d2b466acaac649949b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/434 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ddbb4f311bf4928b2749a7a630fee94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S60IvpkIZ56a"
      },
      "source": [
        "curve_info = learning_curve(BertBreak_MC_MLM, model_checkpoint, datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNdAscPxjZEv"
      },
      "source": [
        "nolang_curve_info = learning_curve(BertBreak_MC_MLM, model_checkpoint, nolang_datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3S65gDtqO3k"
      },
      "source": [
        "nolang_curve_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPUF6j4LtfFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0144db-3083-4ad0-bda9-c7e74a7eefc7"
      },
      "source": [
        "curve_info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{64: 0.2673611111111111,\n",
              " 128: 0.3784722222222222,\n",
              " 256: 0.5520833333333334,\n",
              " 512: 0.84375,\n",
              " 1024: 1.0,\n",
              " 2048: 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt94i5xwbOM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8dedf46c-c164-46ce-b13c-8288b776bee8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# roberta - break\n",
        "curve_info = {64: 0.23133680555555555,\n",
        " 128: 0.2387152777777778,\n",
        " 256: 0.28515625,\n",
        " 512: 0.38237847222222227,\n",
        " 1024: 0.4735243055555556,\n",
        " 2048: 0.4735243055555556,\n",
        " 4096: 0.4735243055555556}\n",
        "nolang_curve_info = {64: 0.2191840277777778,\n",
        " 128: 0.2673611111111111,\n",
        " 256: 0.39409722222222227,\n",
        " 512: 0.48046875,\n",
        " 1024: 0.5264756944444444,\n",
        " 2048: 0.5264756944444444,\n",
        " 4096: 0.5264756944444444}\n",
        "##########################################\n",
        "#  bert - break:\n",
        "nolang_curve_info = {64: 0.1918402777777778,\n",
        " 128: 0.22005208333333334,\n",
        " 256: 0.4153645833333333,\n",
        " 512: 0.7365451388888888,\n",
        " 1024: 0.9079861111111112,\n",
        " 2048: 1.0,\n",
        " 4096: 1.0}\n",
        "curve_info = {64: 0.19835069444444445,\n",
        " 128: 0.22743055555555555,\n",
        " 256: 0.3298611111111111,\n",
        " 512: 0.3936631944444444,\n",
        " 1024: 0.4752604166666667,\n",
        " 2048: 0.4752604166666667,\n",
        " 4096: 0.5052604166666667}\n",
        "plt.plot(list(curve_info.keys()), list(curve_info.values()), 'bo')\n",
        "plt.plot(list(curve_info.keys()), list(curve_info.values()), 'b-',label = 'Breakable')\n",
        "\n",
        "plt.plot(list(nolang_curve_info.keys()), list(nolang_curve_info.values()), 'ro')\n",
        "plt.plot(list(nolang_curve_info.keys()), list(nolang_curve_info.values()), 'r--',label = 'Breakable nolang')\n",
        "\n",
        "plt.xscale('log', basex=2)\n",
        "plt.legend()\n",
        "from google.colab import files\n",
        "plt.savefig(\"abc.png\")\n",
        "files.download(\"abc.png\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5cbc18b7-3096-4f01-bc49-bdd78fc91e78\", \"abc.png\", 13414)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yUVdbA8d9JQqQJKuCCQAhgFkSRYqQpigUUESKgK4qKBYMKiroWithZXfHdFZVXCSi4a1wVFYguChYU5bUQXVSKSpESZKV3CCnn/eMmYZJMkiGZ5JmZnO/nM5+ZeZ6bZ84l4eTmPreIqmKMMSb8RXkdgDHGmOCwhG6MMRHCEroxxkQIS+jGGBMhLKEbY0yEsIRujDERIsarD27YsKHGx8d79fHGGBOWvv32222q2sjfOc8Senx8POnp6V59vDHGhCURWV/SOetyMcaYCGEJ3RhjIoQldGOMiRCe9aH7k5WVRUZGBocOHfI6FFOJatasSbNmzahRo4bXoRgTUcpM6CLyMnApsEVVT/NzXoDJwCXAAeB6Vf2uPMFkZGRw7LHHEh8fj7usiTSqyvbt28nIyKBly5Zeh2PCQWoqjB8PGzZAXBxMnAhDh3odVflUcl0C6XKZCVxcyvm+QELeIxl4obzBHDp0iAYNGlgyj2AiQoMGDeyvMBOY1FRITob160HVPScnu+PhpgrqUmYLXVUXiUh8KUWSgH+oW4f3KxE5TkSaqOrm8gRkyTzy2ffYBGz8eDhwoPCxAwfgnnuOtGw/+AAOHy5cplkz6NzZvX7vPcjNLXw+Ph5OP90df++94p978snQrp277gcfFD/fti388Y8ulo8+Kn7+tNOgVSvYswc+/dQdu+su/3UZPz54rXRVLfMBxAPLSjj3HnC2z/uPgcQSyiYD6UB6XFycFrVixYpix6paVFSUdujQQU8//XTt1KmTLl68OCjX/fXXX/XUU08NuPyMGTN05MiRfs/VqVMnKDF5KRS+1yYMuLas/0e+Bg2Kn7vuuiPnY2OLn8//v5WZ6f/aY8a489u3+z8/caI7v26d//OTJ7vzP/5Yeh1AVeQo/0lI1xJydZXeFFXVFCAFIDExMSR31qhVqxZLly4FYP78+YwdO5bPPvusUJns7GxiYkLqfrIxkWP/fpgzB66+Glq0cF0TRZ100pHXH38MOTmFz59wwpHXX33lUqevRnkTLWNi4Ntvi1//D39wz/Xq+T+f//mNG/s/36yZe27d+sj5fv3gv/8tXjYurvixcgpGVtoENPd53yzvWNjbs2cPxx9/PACffvopEyZM4Pjjj+enn35i5cqVjBkzhk8//ZTMzExGjhzJiBEj2LdvH0lJSezcuZOsrCwef/xxkpKSCl137dq1DB48mJSUFFSV0aNHc+jQIWrVqsWMGTNo06YNABs3bqRXr15s2rSJa665hoceeqhYjJMmTeLNN98kMzOTgQMH8sgjj1T+P4wxlSEjA55/HlJSYOdOSEhwNw2Tkwt3VdSuDU89deR9hw6lX7dTp5LPRUUd6ZrxJyam9PPHHFP6+Vq1jpx/+mn/dZk4seSvP0rBSOhpwCgReR3oCuzWcvaf+7rzTshrKAdNx47wzDOllzl48CAdO3bk0KFDbN68mU8++aTg3HfffceyZcto2bIlKSkp1K9fnyVLlpCZmclZZ51Fnz59aN68ObNnz6ZevXps27aNbt26MWDAgIJr/PzzzwwZMoSZM2fSoUMH9uzZw+eff05MTAwfffQR48aN4+233wbgm2++YdmyZdSuXZszzzyTfv36kZiYWHCtBQsWsGrVKr755htUlQEDBrBo0SLOOeec4P7DGVOZtmyBu++GN95wfdoDB7r3Z54JXbq4MpEwyiU/5kqsSyDDFv8F9AIaikgG8BBQA0BVXwTm4YYsrsYNW7whaNF5wLfL5csvv+S6665j2bJlAHTp0qVgqN2CBQv44YcfeOuttwDYvXs3q1atolmzZowbN45FixYRFRXFpk2b+P333wHYunUrSUlJvPPOO7Rr167g64YNG8aqVasQEbKysgpi6d27Nw0aNABg0KBBfPHFF8US+oIFC+iU1wLZt28fq1atsoRuQl9ODmzc6G5O1qvnukVGjYI77oCiw1mHDg3PBO5PJdclkFEuV5VxXoGRQYsoT1kt6arQvXt3tm3bxtatWwGoU6dOwTlV5bnnnuOiiy4q9DUzZ85k69atfPvtt9SoUYP4+PiCIXr169cnLi6OL774oiChT5gwgfPOO4/Zs2ezbt06evXqVXCtoqNBir5XVcaOHcuIESOCVmdjKtW+fTBzJkye7JL6qlVQsyb8/DNER3sdXdizqf+l+Omnn8jJySloJfu66KKLeOGFFwpa1L/88gv79+9n9+7dnHjiidSoUYOFCxey3ueGTmxsLLNnz+Yf//gHr732GuBa6E2bNgXcLwNfH374ITt27ODgwYPMmTOHs846q1gML7/8Mvv27QNg06ZNbNmyJWj1NyZoNm2CMWOgeXO4/XZo2BCefPLIeUvmQWFDNYrI70MH1wJ+5ZVXiPbzwzZ8+HDWrVtH586dUVUaNWrEnDlzGDp0KP3796d9+/YkJibStm3bQl9Xp04d3nvvPXr37k3dunW57777GDZsGI8//jj9+vUrVLZLly4MHjyYjIwMrrnmmkLdLQB9+vRh5cqVdO/eHYC6devy6quvcuKJJwbzn8SY8svJcck6PR0mTYLBg9147LyfWRNcokWH81SRxMRELboe+sqVKznllFM8icdULfteR7CcHEhLg7/9DXr1gscec8cyMtwwRFMhIvKtqib6O2ddLsaY4Ni7F5591s2gHDSocAKPjrZkXgWsy8UYExy33urWJenRA/76V7jsMjeO21QZa6EbY8rnm29gyBD46Sf3fuxYN/xw8WK4/HJL5h6whG6MCVxODrz9Npx9NnTtCu+/DytWuHOnnuqOGc/Yr1BjTGByctwKhStWuMk/zzwDN94Ixx7rdWQmjyV0Y0zJ1q+H2bPdWhzR0TB8uLu5mZRkY8dDkHW5FBEdHU3Hjh3p0KEDnTt35v/+7/+Cct1169Zx2mnFNnwq0cyZMxk1apTfc3Xr1g1KTCV5+OGHefrppyv1M0yI++oruPJKt1rgPfe4GZ3gxpAPGmTJPERZQi8ify2X77//nieeeIKxY8cWK5Odne1BZMZUgTVr3CiV7t1h/ny3SNavv7qVD03Is4ReiqLL5/bs2ZMBAwbQrl07cnJyuPfeeznzzDM5/fTTmTp1KuAWyLrgggvo3Lkz7du3Z+7cucWuu3btWjp16sSSJUv45ptv6N69O506daJHjx78/PPPBeXyl89NSEgocVncSZMmFcTgb3ldcC368ePH06FDB7p161awWNi6des4//zzOf3007ngggvYsGFDsa+dNm0aZ555Jh06dGDw4MEcyFv68/rrr+eOO+6gR48etGrVqmCRstzcXG677Tbatm1L7969ueSSSwrOmRC1ezd8/7173aSJ6yt/9lk3jvypp9x0fRMeStr5orIfZ5xxRrGdOIrtYnPuucUfU6a4c/v3+z8/Y4Y7v3Vr8XMByN+xqE2bNlqvXj1NT09XVdWFCxdq7dq1de3ataqqOnXqVH3sscdUVfXQoUN6xhln6Nq1azUrK0t3796dF8JWbd26tebm5hbsWPTTTz9px44ddenSpaqqunv3bs3KylJV1Q8//FAHDRqkqm7HosaNG+u2bdv0wIEDeuqpp+qSJUtU9ciORfPnz9ebb75Zc3NzNScnR/v166efffZZsToBmpaWpqqq9957b0Hcl156qc6cOVNVVV966SVNSkpSVdWHHnpIJ02apKqq27ZtK7jO+PHj9dlnn1VV1WHDhunll1+uOTk5unz5cm3durWqqs6aNUv79u2rOTk5unnzZj3uuON01qxZxWKyHYtCwNq1qnfeqXrssaoJCao5OV5HZAJAqOxYFA4icfnc2NhYLr30UgDOOOMMPvzww4L6vfPOOwBce+213HfffcX+PZYtW8YDDzzArl272LdvX6HVJS+77DKioqJo165dQR2/+OILrrjiCqKiomjcuDHnnXfeUX4HTKVbutStw/3OO26DhyuvdH3jUfYHe7gL7YSev7mqP7Vrl36+YcPSzwcgUpbPrVGjRsHXRkdHH9U9gOuvv545c+bQoUMHZs6cyac+/6bHHHNMoVhMCElNLbyRwqOPusk+tWvD6tVuY+P77oORI49sl2bCnv1KLkWkL5/bo0cPXn/9dQBSU1Pp2bNnsTJ79+6lSZMmZGVlkZqaWuY1zzrrLN5++21yc3P5/fffC/0CMFUkNdVtdbZ+vdtLc/16uP56uO46d/6yy9zmEk88Yck8wgTUQheRi4HJQDQwXVWfLHK+BfAy0AjYAVyjqhlBjrVKVKflc5977jluuOEGJk2aRKNGjZgxY0axMo899hhdu3alUaNGdO3alb1795Z6zcGDB/Pxxx/Trl07mjdvTufOnalfv35A8ZggGT++8L6V4BL755+71zExUMlDX403ylw+V0SigV+A3kAGsAS4SlVX+JSZBbynqq+IyPnADap6bWnXteVzI9e+ffuoW7cu27dvp0uXLixevJjGjRsXKmPf60oUFVV8l3sAEbdnpwlrpS2fG0gLvQuwWlXX5l3sdSAJWOFTph1wd97rhcCc8odrwt2ll17Krl27OHz4MBMmTCiWzE0li4tz3Sz+jpuIFkhCbwps9HmfARRdged7YBCuW2YgcKyINFDV7b6FRCQZSAaIsx+uiGX95h75/nt45RV4/HEYMaJwt0vt2m5ki4lowbopeg9wroj8BzgX2ATkFC2kqimqmqiqiY0aNQrSRxtjmD3bzfB880047zxISXFrroi455SUSt1t3oSGQFromwDfqWLN8o4VUNXfcC10RKQuMFhVd5UnIFUtNjzPRBYb4hhEqq5F/uCDbuna2bPdbM+hQy2BV0OBtNCXAAki0lJEYoEhQJpvARFpKCL51xqLG/Fy1GrWrMn27dvtP3wEU1W2b99OzZo1vQ4lMtx2m0vm11zj5l00aeJ1RMZDZbbQVTVbREYB83HDFl9W1eUi8ihuCmoa0At4QkQUWASMLE8wzZo1IyMjo2Aij4lMNWvWpJmNfw6OP/0J4uPdJCH7y7baK3PYYmXxN2zRGBOAr79227/dfrvXkRgPlDZs0WaKGhNOXn0Vzj0XJk8uPnnIVHuW0I0JB7m5bhPma6+Fbt3cBhS1a3sdlQkxob04lzHGjWS54gq3OuKIEW6t8thYr6MyIcgSujGhTgQuvBDOP9+NarGbn6YEltCNCVWLFsHevdCvH9x6q9fRmDBgfejGhKJp0+CCC+Dhh21BLRMwS+jGhJLsbBg92q1nfsEF8OGHtpOQCZh1uRgTKg4dggEDXBK/6y63QXOM/Rc1gbOfFmNCxTHHQJs2MGQI3Hij19GYMGQJ3RivLVgAJ50Ep50Gzz3ndTQmjFnnnDFeUXUzPvv2hQce8DoaEwGshW6MFw4fhpEjYfp0SEpyU/qNqSBroRtT1XbudBOFpk93Gzq/845t2myCwlroxlS1OnWgVi147TW46iqvozERxBK6MVXl/fehSxdo0AA++MCm8JugC6jLRUQuFpGfRWS1iIzxcz5ORBaKyH9E5AcRuST4oRoTplThiSfcFP5HH3XHLJmbSlBmC11EooEpQG8gA1giImmqusKn2APAm6r6goi0A+YB8ZUQrzHh5eBBGD7cda9cfTU8+aTXEZkIFkgLvQuwWlXXquph4HUgqUgZBerlva4P/Ba8EI0JU5s3Q69eLpn/5S9uJEutWl5HZSJYIH3oTYGNPu8zgK5FyjwMLBCR24E6wIX+LiQiyUAyQFxc3NHGakx4iY6Gfftgzhw3NNGYShasYYtXATNVtRlwCfBPESl2bVVNUdVEVU1s1KhRkD7amBDz4YeQlQUnngg//GDJ3FSZQBL6JqC5z/tmecd83QS8CaCqXwI1gYbBCNCYsJGb62Z89ukDzz/vjkVHexuTqVYCSehLgAQRaSkiscAQIK1ImQ3ABQAicgouoW8NZqDGhLR9+2DwYJg4EW66yc0CNaaKldmHrqrZIjIKmA9EAy+r6nIReRRIV9U04M/ANBG5C3eD9HpV1coM3JiQsX69W/Z22TJ45hm44w4blmg8EdDEIlWdhxuK6HvsQZ/XK4CzghuaMWFi507Yvh3mzYOLLvI6GlON2UxRY8rrq6+gWzfo2BHWrHHrmRvjIVucy5ijlZ0Nd98N3btDWt7tJEvmJgRYC92Yo7Frl9tRaP5811d+ia1yYUKHJXRjArVqFfTv77pXpk51GzkbE0IsoRsTqB9+gB074KOP4NxzvY7GmGKsD92Y0qjCypXu9eDBsHq1JXMTsiyhG1OSrCy47Tbo0AG+/94dq1ev9K8xxkOW0I3Jl5oK8fEQFQXNm7tE/uKLcM890L6919EZUybrQzcGXDJPToYDB9z7jAz3fOutbulbY8KAtdCNAbdZc34y9zVvXvFjxoQoS+jGAGzYcHTHjQlBltCNAShpwxXbiMWEEUvoxgCMGlX8WO3abjlcY8KEJXRjcnPh3XddAm/a1C1926IFpKTA0KFeR2dMwGyUizHTpsGiRTB9utucwpgwFVALXUQuFpGfRWS1iIzxc/7vIrI07/GLiOwKfqjGVILffoN774Xzz4cbb/Q6GmMqpMwWuohEA1OA3kAGsERE0vI2tQBAVe/yKX870KkSYjUm+Bo1gnHj4IorbJchE/YCaaF3AVar6lpVPQy8DpS2jflVwL+CEZwxlUoVatSAMWOgdWuvozGmwgJJ6E2BjT7vM/KOFSMiLYCWwCcVD82YSrR9O3TqBB9/7HUkxgRNsEe5DAHeUtUcfydFJFlE0kUkfevWrUH+aGOOwl13wfLlrsvFmAgRSELfBDT3ed8s75g/Qyilu0VVU1Q1UVUTG9l/JOOVDz6Af/7TdbWcfrrX0RgTNIEk9CVAgoi0FJFYXNJOK1pIRNoCxwNfBjdEY4Jo3z4YMQLatoUHHvA6GmOCqsxRLqqaLSKjgPlANPCyqi4XkUeBdFXNT+5DgNdVVSsvXGMq6NVXYeNG+Pxz29jZRBzxKv8mJiZqenq6J59tqjFV+PZbSEz0OhJjykVEvlVVvz/ANvXfVA+ZmbBunRtrbsncRChL6KZ6+Mtf4NRTXXeLMRHKErqJfD/+6BL6wIFuazljIpQldBPZcnLcglvHHQfPPON1NMZUKltt0US2yZNhyRJ47TVo2NDraIypVNZCN5Htt9+gf38YMsTrSIypdNZCN5Ht6achO9tWUjTVgrXQTWSaMwe+/tq9jrF2i6ke7CfdRJ7Nm+GGG6BDB1i40FrnptqwFrqJPLffDgcPwtSplsxNtWItdBNZ3nkH3n7bjTtv08braIypUtZCN5Fj1y4YORI6doR77vE6GmOqnLXQTeSoUwdGj4Y+fdzWcsZUM5bQTWTw3R/UmGrKulxM+DtwAHr2hPff9zoSYzxlCd2EvwcfhMWLoVYtryMxxlMBJXQRuVhEfhaR1SLi929aEfmTiKwQkeUi8lpwwzSmBEuWwN//DsnJ0KuX19EY46ky+9BFJBqYAvQGMoAlIpKmqit8yiQAY4GzVHWniJxYWQEbU+DwYbeSYuPG8NRTXkdjjOcCuSnaBVitqmsBROR1IAlY4VPmZmCKqu4EUNUtwQ7UmGLeesutdT53LtSv73U0xngukITeFPDd5iUD6FqkzB8BRGQxbiPph1X1g6IXEpFkIBkgLi6uPPEac8RVV7kNK3r29DoSY0JCsG6KxgAJQC/gKmCaiBxXtJCqpqhqoqomNmrUKEgfbaqd3FzYsMFN67dkbkyBQBL6JsB3365mecd8ZQBpqpqlqr8Cv+ASvDHB98ILcMopsHKl15EYE1ICSehLgAQRaSkiscAQIK1ImTm41jki0hDXBbM2iHEa42zY4CYPnX02tG3rdTTGhJQyE7qqZgOjgPnASuBNVV0uIo+KyIC8YvOB7SKyAlgI3Kuq2ysraFNNqcItt7hnW0nRmGICmvqvqvOAeUWOPejzWoG78x7GVI7XXnOzQZ95BuLjvY7GmJBjM0VN+FixAnr0gFGjvI7EmJBki3OZ8DFxoptMFB3tdSTGhCRroZvQt3AhfPWVex0b620sxoQwa6Gb0LZnD1x3HZxwAvznPxBlbRBjSmIJ3YS2MWNg0yY3zd+SuTGlsv8hJnR9/rmbRDR6NHQtutqEMaYoS+gmNB06BMOHu+GJjz/udTTGhAXrcjGhKSbGLY3bqZPbK9QYUyZL6CY0xcTAffd5HYUxYcW6XExoyc6Gfv3g3Xe9jsSYsGMJ3YSWv/0N5s1zfejGmKNiCd2EjlWr4KGH4LLL4PLLvY7GmLBjCd2EhtxcuPlmOOYYmDLFVlI0phzspqgJDR98AJ99BtOmwUkneR2NMWHJWugmNPTtC/Pnu6GKxkSo1FQ3tSIqyj2npgb3+gEldBG5WER+FpHVIjLGz/nrRWSriCzNewwPbpgmYqnC5s2ui6VPH+tqMRErNRWSk2H9evdjv369ex/MpF5mQheRaGAK0BdoB1wlIu38FH1DVTvmPaYHL0QT0WbNgtatYckSryMxplKNGwcHDhQ+duAAjB8fvM8IpA+9C7BaVdcCiMjrQBKwInhhmGpp+3a4/XZo187NCDUmzOXkuG1vV60q/tiwwf/XlHS8PAJJ6E2BjT7vMwB/KyUNFpFzgF+Au1R1o58yxhzx5z/Djh2wYIGbGWpMGMjNdQuA+kvaa9a4PVjy1a4NCQnQoQP8/rtbDbqouLjgxRas/0XvAv9S1UwRGQG8ApxftJCIJAPJAHHBrIUJPwsWwCuvuL9DO3TwOhpjCsm/teMvaa9eXXjeW82artewTRu49FKXwP/4R/fcpMmR20L5fei+3S61a7uNuIIlkIS+CWju875Z3rECqrrd5+104Cl/F1LVFCAFIDExUY8qUhNZvvkGTjkFJkzwOhJTTanCli0lJ+39+4+UjY2FVq1cku7Txz3nP5o1C2yp/qFD3fP48a6bJS7OJfP848EgqqXnVRGJwXWjXIBL5EuAq1V1uU+ZJqq6Oe/1QOB+Ve1W2nUTExM1PT29guGbsHbggGuiGFNJVN2tmpKStm8XSEwMtGxZOFnnP+LiQmcrWxH5VlUT/Z0rs4WuqtkiMgqYD0QDL6vqchF5FEhX1TTgDhEZAGQDO4Drgxa9iSzffus6Gbt3t2ReiVJTK7clWJUCqcuuXS5J//JL8cS9a9eRcvnjvxMSoEePwkm7RQuoUaNKqxZ0ZbbQK4u10KuhzEzo3Nn9LbtqVfj/7wlRJfXVpqSEX1L3V5fYWBgwwNUpP2lv23bkvIhL/P5a2i1bhv8+46W10C2hm6rz8MPwyCPw73/DJZd4HU3EatHC/1A4EahVq+rjqYiDB123iT9Nmx5J1Pk3IRMSXF93zZpVG2dVqlCXizFBsWwZ/OUvcPXVlswryfLlbimcksY1q8Jtt1VtTBX19NMln8vIqLo4woUldFP5cnLc/qD16sEzz3gdTUTZvx/eeMMl8q++cr1YtWsXn5EIruU+aVLVx1gRs2a5KfJFtWhR9bGEA1ucy1Q+VRg82C2L26iR19GEPVVIT4dbbnHjnG+6yd34e/ppN+ElJaX4/eZgj3euKhMnRk5dqoK10E3li4mBe+/1Ooqwt2sXvPaaa40vXer6w6+4wi0jf9ZZRyawVMV456oSSXWpCnZT1FQeVbjuOhg0CAYO9DqasKQKixe7JD5rlrtJ2LGjS+JXXw3HHed1hKaq2U1R441XXoFXX4Vupc4xM35s3Qr//CdMnw4rV8Kxx7rfjcOHwxln2CrDxj9L6KZy/P473H236wu49VavowkLubnwySeuNT57NmRluflXL70Ef/oT1K3rdYQm1FlCN5Xj9tvdEIzp0wNb6KIa++03mDHDJe5ff4Xjj3fDC4cPh9NO8zo6E04soZvgW7zYdfg+/ji0bet1NCEpOxvef9/9vvv3v93IzvPOczf8Bg6M7IkxpvJYQjfB16MHpKXBxRd7HUnIWbfOtcRfftm1zP/wB7jnHjf0MCHB6+hMuLOEboJr2zZo2BD69/c6kpBx+DDMnev6xj/6yB27+GJ4/nm3frYtaWOCxTo3TcXlb2UuAieeCA884HVEIeHnn13ru2lTd1Pzp5/goYdcK33ePNe1YsncBJO10E3FFF0OTxX+9je3eUU1nP1x8CC89ZZrjX/+uZtT1b+/Gzfep0/orKltIpNNLDIVEx9f8mIb69ZVdTSe+f57l8RffRV274aTT3ajVIYNg8aNvY7ORBKbWGQqT1VsZR6i9u6Ff/3LJfL0dDjmGLdkzc03w7nn2uQfU/UC6kMXkYtF5GcRWS0iY0opN1hEVET8/vYwEaikzb4jdBNwVfj6a9f6btIERoxw3SzPPONGraSmQq9elsyNN8psoYtINDAF6A1kAEtEJE1VVxQpdywwGvi6MgI1IUYVNm50A6dvvtlltXwRuBzejh2uO2XaNLe0e+3aMGSIq3rXrpbATWgIpIXeBVitqmtV9TDwOpDkp9xjwF+BQ0GMz4Si3Fw3lbFjR9e3MG2a6zMXcc/huNcZRwbr5O87+eqr8OmncM01cNJJMHq0m/AzdSps3uzGk3frZsnchI5A+tCbAht93mcAXX0LiEhnoLmq/ltESlwnVUSSgWSAuAj9kzziZWXB9de7dVzvv9+NyRs6NCwTuK+ig3XWr3eLYalC/fqui2X4cPc7zJhQVeGboiISBfwNuL6ssqqaAqSAG+VS0c82VezQIbjySjcL9IknYEyJt1PCzv33F9/lRxUaNHD3d4tusmBMKAokoW8Cmvu8b5Z3LN+xwGnAp+L+9mwMpInIAFW1cYmR5KmnXDKfMiX8NqcsQhW++87N4Jw71+3048+OHZbMTfgIJKEvARJEpCUukQ8Brs4/qaq7gYb570XkU+AeS+YR6L77oEuXsF2j5fBhWLjQ/U5KS3ObDEdFuRV+jzvO7QhUlPUMmnBS5k1RVc0GRgHzgZXAm6q6XEQeFZEBlR2g8djvv7v+8Z073R3BMGXAQUwAAA4sSURBVEvmO3e67v4rr3RLzFx8McycCWee6Zas/e9/YdEit66K7V1pwp3NFDUl27ABLrzQ9UcsWOCasmFg3TrXAp871yXr7Gy3qmH//pCUBBdc4PbjLCo11fauNKGvtJmiltCNf7/84pL5nj1uJakePbyOqERF+8N/+MEdP+UUl8CTklxPke2zYSKBTf03R2fZMteMVXUDsUNwrF5mpgtt7lzXGt+06Uh/+NNPw4ABtr64qX4soZvijj/e7TSUkgJt2ngdTYGdO90fC2lpbrefvXtdP/dFF7lW+CWXQKNGXkdpjHcsoZsjli6F9u3dZKFPPw2JKZAl9YcPGeJa4SX1hxtTHVlCN87cuW4XhvHj4cEHPUvmJfWHt2vnNouw/nBjSmYJ3bjhHcOGwRlnwKhRVf7x1h9uTHBYQq/uXngBRo50a77OnQvHHlslH1tWf3i/fm7cuDEmcJbQq7PffnP9GJdeCm++6SYOVaLS+sOTkuD8860/3JiKsIRenZ10EnzxBZx2WoV2Ky5pQk5p/eH33uu6Uqw/3JjgsYlF1U1uLtxxh0vit9xS4csVXXYW3FZsZ5/tdrnP7w8/+2yXwJOS3H6bxpjysYlFxsnOhhtvhH/+0y20FQTjxxdfdjYzEz75BAYOdEnc+sONqRqW0KuLzEzXWT1nDjz+OIwbV+FLZmW5jSD8UYW3367wRxhjjoL1XlYHOTluZao5c2DyZNesrsA486wst/1a27Yll2nRotyXN8aUkyX06iA62o0HnDHD9Z+X0+HDbjWAhAS3HdsJJ8DddxcfmWLLzhrjDetyiWRbtrixgl26wJ//XO7LZGbCyy+7Xec2bnSX+9//hb59XUO/c2dbdtaYUBBQC11ELhaRn0VktYgU20hSRG4RkR9FZKmIfCEi7YIfqjkqGzdCz55w2WVw8GC5LnHokNv4oXVrt+Ncs2bwwQfw1VduIaz8XpuhQ93vjdxc92zJ3BhvlJnQRSQamAL0BdoBV/lJ2K+pantV7Qg8hds02nhl1So3TvC//3UTho5yts7Bg66rvVUruP129/zRR7B4seu5CYE1u4wxfgTS5dIFWK2qawFE5HUgCViRX0BV9/iUrwN4M7jdwI8/Qu/e7kbowoWuPyRA+/fDiy/CpElu57levdw48169LIkbEw4CSehNgY0+7zOArkULichI4G4gFjg/KNGZo/f88xAT45L5KacE9CX79rk+8aefhq1b3ZK0b74J55xTybEaY4IqaKNcVHWKqrYG7gce8FdGRJJFJF1E0rdu3RqsjzbgWuQAzz3nOrkDSOZ797obnfHxcP/90KmTWwngo48smRsTjgJJ6JuA5j7vm+UdK8nrwGX+TqhqiqomqmpiI9taJnjefRcSE92olthYd/eyFLt3u7lF8fFuflGXLvDllzB/ftjsA22M8SOQhL4ESBCRliISCwwB0nwLiIjvatX9gFXBC9GU6l//cnPsa9Rw481LsWsXPPKIS+QTJrjk/c03bhnbbt2qJlxjTOUpsw9dVbNFZBQwH4gGXlbV5SLyKJCuqmnAKBG5EMgCdgLDKjNokyclxS2wdc45rpVewlrmO3bAM8+4kSt79riRjBMmHNX9UmNMGAhoYpGqzgPmFTn2oM/r0UGOy5Rl5kwYMcKtfDVrlt+hidu2wd//7rrV9+6FwYPhgQegY8eqD9cYU/ls6n+46tvXbU4xe3axZL51q7vJGR/vbnr27evWIn/rLUvmxkQyS+jhJDcXpk93q2P94Q9uwLjPxhS//+5yfHy8OzVgACxbBm+8Ae3bexe2MaZq2Fou4SI7262I9corbvWrq68uOLV5Mzz1FEyd6tZdufpqt7ZKaashGmMijyX0cJCZ6RZIefttN0zlqqsAtxvQX//q7o1mZ8O117phiAkJZVzPGBORLKGHuv37YdAgWLDADVUZPZqNG+HJJ13vS24uDBsGY8e6RbSMMdWXJfRQt3atGyz+0kusO/9GnrzFLWULcMMNMGYMtGzpbYjGmNBgCT1UHTjg+srbt2fdx2uY+MIJzBzhNlwePtwl8rg4r4M0xoQSS+ihKCMDLryQrZffyv2/jeYf/ziBmBg3h+j++8uc2W+MqaYsoYea1avJ6nUh2Vt28KcnOvFVLIwaBffdByed5HVwxphQZuPQPZKa6saLR0W559RUWJu2jJ3te7J70z56R31C5zvP4ddf3b1QS+bGmLJYC90DqamQnOy6yQHWr4fR1+3kp9xeHJJYUm9YxDtPtuPEE72N0xgTXqyF7oFx4yDpQCq/Ek8OUfxKPH1y5/FAzf8h9usvuOdlS+bGmKNnLfRKkpkJv/4Kq1e7x5o1R16ftSGVaSRTB9dEj2c900gm+VAKDc5s5XHkxphwZQm9Ag4ccMPE8xO172PDBlCfnVXr1YOTT4az2u/hydX3FCTzfHU4wF+jxwNDq7YSxpiIYQm9DHv2FG5d+7a4NxXZt6lBA0honcuATpvo3GsNbWLWEJe1hoa71xD7wmSkSWN4YgrM/q/fz2qas6EKamSMiVSW0HEbQBTtFsl/bNlSuGzjxtCu1SGuO/NXOpy3hoSoNTTNXEvNO2+hfrdT4NXX3KIq+WJioEUL2LoFmjR20/j//ne3xm0R0sJmChljyi+ghC4iFwOTcTsWTVfVJ4ucvxsYDmQDW4EbVXV9kGMtN1WXP/11jaxeDTt3Fi7frKnSOX4Hl3RfS/vaa2jFGmIv6c1Jl3Wh7o9fQo8ehb+gbl24pjdwCpx9Nrz4oltYpXVraN7cJfV8bdq4hO47zAXcrNCJEyvt38AYE/nKTOgiEg1MAXoDGcASEUlT1RU+xf4DJKrqARG5FXgKuDLYwaamumVhN2xw094nTnSLEIJbpGrzZv9dI6tXux178kVFQcu4HLo1y+Dqs9dwas011OrUlhOSetIydhO1Ek+FxbsLf3iXOlC3i1vK8JFHjiTs1q2hYUMQceXi491OQqXJD7qkyhhjTDmI+t6581dApDvwsKpelPd+LICqPlFC+U7A86pa6v7xiYmJmp6eHnCgqanw0Q2pPJQ1njg2sIE4JshEVnYeSmamS9wHDx4pHxMDp8Qf5Kwma+lcfw0ntKxP7b7n0jo+h4SBpyFr17iNIvLddhtMmeLWob3zTmjV6kjCbtkS6tQJOFZjjKksIvKtqib6OxdIl0tTYKPP+wygaynlbwLeLyGQZCAZIO4oV5b6enQqz2cVHur3ot7MPd/tpe7ZnWjR/zDRvXpy8snQ4+lB1P7xK2T1Zlidd4H+/aHvuUA0nHsOXJZ0JGG3auW6RsD9Jnj++aOKzRhjQkFQb4qKyDVAInCuv/OqmgKkgGuhH821794+3s9Qv4O8oLfC50CHDvDGUndiThM46aLC3SInn3zkC6dOPZqPNsaYsBBIQt8ENPd53yzvWCEiciEwHjhXVTODE94Rcfgf0pcLRKWlFd6mZ8qUYH+8McaEvECm/i8BEkSkpYjEAkOANN8Cef3mU4EBqrrFzzUq7EAD/100Bxq0cN0ptoGmMaaaKzOhq2o2MAqYD6wE3lTV5SLyqIgMyCs2CagLzBKRpSKSVsLlyq3u5Ilkx9YudCw7tjZ1J9tQP2OMgQD70FV1HjCvyLEHfV5fGOS4ihs61AXrM9Qvxob6GWNMgfCaKTp0qCVwY4wpgS2fa4wxEcISujHGRAhL6MYYEyEsoRtjTISwhG6MMRGizMW5Ku2DRbYC5V1ityGwLYjheMnqEnoipR5gdQlVFalLC1Vt5O+EZwm9IkQkvaTVxsKN1SX0REo9wOoSqiqrLtblYowxEcISujHGRIhwTegpXgcQRFaX0BMp9QCrS6iqlLqEZR+6McaY4sK1hW6MMaYIS+jGGBMhLKEbY0yECK/lc32ISBTwGFAPSFfVVzwOqdxEpCcwFPf9aKeqPTwOqdxEJA54FtgB/KKqT3ocUrmISDvgYWA78LGqvuVtREdPRFrhtoWsr6qXi0gd4H+Bw8CnqprqaYBHwU9dCr33NrrA+anHZUA/XB57SVUXVOT6Id9CF5HmIrJQRFaIyHIRGZ13Kgm3v2kWkOFdhIErqS6q+rmq3gK8B4TFL6ZSvi/tgbdU9Uagk4chBqSUevQFnlPVW4HrPAyxTKX8XK1V1Zt8ig7CfW9uBgb4vZjHAq2Ln7qFlKOox5y878ctwJUV/mBVDekH0ATonPf6WOAXoB0wBhiRd/wtr+OsSF18zr8JHOt1nBX8vjQAFgKfADd4HWcF6nEiMAW3veJir+Os4M/VW3nPY4GOea9f8zruitSlpPeh8ihHPf4nv3xFHiHfQlfVzar6Xd7rvbh9TZviWuU784rleBTeUSmlLvldFbvzjoe8UupyA/CQqp6P+1MypJVUD1XdoqojcQ2HkF4/pLSfqyIycH/VQoj+dX4UdQlpgdZDnL8C7+eXr4iw6kMXkXjcn/FfA9nAc3n9z4s8DKtcitQF4CZghlfxVESRumwGHhaRq4F13kV19Hzrkfd6HFAH10oPC0Xq0ACYCHQSkbG4exvPi0g/4F3PggxQGXVJ8X2vqk94FmgZyqjHfuBCoL6InKyqL1bos/Ka+yFPROoCnwETVfUdr+OpCKtL6ImEekRCHfJFSl2quh4h+WdXUSJSA3gbSA3nby5YXUJRJNQjEuqQL1Lq4kU9Qr6FLiKCG/mxQ1Xv9DqeirC6hJ5IqEck1CFfpNTFq3qEQ0I/G/gc+BHIzTs8TlXneRdV+VhdQk8k1CMS6pAvUuriVT1CPqEbY4wJTFj0oRtjjCmbJXRjjIkQltCNMSZCWEI3xpgIYQndGGMihCV0Y4yJEJbQjTEmQlhCN8aYCGEJ3RhjIsT/AwqZguAro5gHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C15-DkBh3KJa"
      },
      "source": [
        "# Breakable task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddg1nmzR35Bw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c0460b0ec3243b39e1ae2984961bf45",
            "bb0ff0de92e74f9c91903c4d4c21f451",
            "860faba97d1c4ab8b016d2f41b6356c9",
            "6b48b00ccad042c6aa31221b3559d6a1",
            "465d711ca4244dd8a499931451ba25ac",
            "d2f9cccc05604ca38882806f8d9175ce",
            "d508c3133491469ea4e11b769ff8e473",
            "1d15fa8e03414a269a891a8f9366d328",
            "4570079875344bdebb52a8c277ac1cdd",
            "5ba150ef42ce465d999101ec7591061c",
            "e8bf18cd5f4f4941ae01ea5ede62c0c3"
          ]
        },
        "outputId": "6b95cbec-9418-43d3-ad4e-b76c6fbda691"
      },
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM, AutoModelForMaskedLM, AutoTokenizer\n",
        "from torch.nn import functional\n",
        "import torch\n",
        "# model_checkpoint = 'HooshvareLab/roberta-fa-zwnj-base'\n",
        "# model_checkpoint = \"HooshvareLab/albert-fa-zwnj-base-v2\"\n",
        "# model_checkpoint = 'bert-base-multilingual-cased'\n",
        "model_checkpoint = \"HooshvareLab/bert-base-parsbert-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "bertmodel = AutoModelForMaskedLM.from_pretrained(model_checkpoint, return_dict = True)\n",
        "\n",
        "bertmodel.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c0460b0ec3243b39e1ae2984961bf45",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=100000, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQE1FBUI4fb8"
      },
      "source": [
        "# for p in bertmodel.bert.parameters():\n",
        "#   p.requires_grad=False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Ca1dEl4ncQ"
      },
      "source": [
        "# # @title fix label\n",
        "# def fix_labels(ex):\n",
        "#   c=ex['question']['choices']\n",
        "#   # for i in c:\n",
        "#   #   if i['label']==0:\n",
        "#   #     if i['text']=='کوچکتر':\n",
        "#   #       ex['fixed_label']=ex['label']\n",
        "#   #     else:\n",
        "#   #       ex['fixed_label']=1-ex['label']\n",
        "#   ex['fixed_label']=ex['label']\n",
        "  \n",
        "#   ex['question']['stem']=ex['question']['stem'].replace('[MASK]', tokenizer.mask_token + ' ' + tokenizer.mask_token)\n",
        "#   enc=tokenizer.encode_plus(ex['question']['stem'],truncation=True,padding='max_length', max_length=64)\n",
        "  \n",
        "#   ex={**ex,**enc}\n",
        "#   return ex\n",
        "\n",
        "# encoded_dataset = datasets.map(fix_labels)\n",
        "# encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'fixed_label'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPq4Wj194nKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e491d94d-9d1f-42eb-af43-87165d95b9f6"
      },
      "source": [
        "# @title dataset loader\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "# dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "encoded_dataset = prepare_dataset(datasets)\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            encoded_dataset['train'],  # The training samples.\n",
        "            sampler = RandomSampler( encoded_dataset['train']), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            encoded_dataset['validation'], # The validation samples.\n",
        "            sampler = RandomSampler(encoded_dataset['validation']), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            encoded_dataset['test'], # The validation samples.\n",
        "            sampler = SequentialSampler(encoded_dataset['test']), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264/cache-c1dbf9c776b3f6c3.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-be3ea5e40df5363b/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264/cache-67c34b675139acee.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-063584867fd76e67/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264/cache-221c0bd750049485.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP5Cf7I-V9vU"
      },
      "source": [
        "# for i , j in enumerate(test_dataloader):\n",
        "#   print(i,j)\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw3IwYj54zSc"
      },
      "source": [
        "\n",
        "# @title Roberta Break_MC_MLM\n",
        "import torch\n",
        "from torch.nn import functional\n",
        "\n",
        "\n",
        "class RobertaBreak_MC_MLM(torch.nn.Module):\n",
        "  def __init__(self, model, tokenizer):\n",
        "    # print(\"__________-----------------------______________\")\n",
        "    super(RobertaBreak_MC_MLM, self).__init__()\n",
        "    for p in model.roberta.parameters():\n",
        "      p.requires_grad=False\n",
        "    self.model = model\n",
        "    self.model.cuda()\n",
        "    self.tokenizer = tokenizer\n",
        "    # self.options = [self.tokenizer.encode(option)[1:3] for option in options]\n",
        "    # print (self.options)\n",
        "  \n",
        "  def forward(self, ids, mask, labels, options):\n",
        "\n",
        "    output = self.model(ids,attention_mask = mask)\n",
        "    # options = [self.tokenizer.encode(option)[1] for option in options]\n",
        "    logits = output.logits\n",
        "\n",
        "    mask_index = torch.where(ids == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    # softmax = functional.softmax(logits, dim = -1)\n",
        "    # print(softmax.shape)\n",
        "    mask1_word = []\n",
        "    # mask2_word = []\n",
        "    for i in range(0, len(mask_index)):\n",
        "      mask1_word.append(logits[i][mask_index[i]])\n",
        "    mask1_word =  torch.stack(mask1_word)\n",
        "\n",
        "    indices1 = torch.tensor(options).to(device)\n",
        "\n",
        "    predicted1 = []\n",
        "    for i in range(len(mask1_word)):\n",
        "      # print(\"mask, \" , mask1_word[i])\n",
        "      x = [mask1_word[i][j] for j in indices1[i]]\n",
        "      x = torch.stack(x)\n",
        "      # print(x.shape)\n",
        "      predicted1.append(x)\n",
        "\n",
        "    predicted1 = torch.stack(predicted1)\n",
        "\n",
        "    predicted = functional.softmax(predicted1)\n",
        "\n",
        "    return predicted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvYx8ajxrcro"
      },
      "source": [
        "\n",
        "# @title Bert Break_MC_MLM\n",
        "import torch\n",
        "from torch.nn import functional\n",
        "\n",
        "\n",
        "class BertBreak_MC_MLM(torch.nn.Module):\n",
        "  def __init__(self, model, tokenizer):\n",
        "    # print(\"__________-----------------------______________\")\n",
        "    super(BertBreak_MC_MLM, self).__init__()\n",
        "    for p in model.bert.parameters():\n",
        "      p.requires_grad=False\n",
        "    self.model = model\n",
        "    self.model.cuda()\n",
        "    self.tokenizer = tokenizer\n",
        "    # self.options = [self.tokenizer.encode(option)[1:3] for option in options]\n",
        "    # print (self.options)\n",
        "  \n",
        "  def forward(self, ids, mask, labels, options):\n",
        "\n",
        "    output = self.model(ids,attention_mask = mask)\n",
        "    # options = [self.tokenizer.encode(option)[1] for option in options]\n",
        "    logits = output.logits\n",
        "\n",
        "    mask_index = torch.where(ids == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    # softmax = functional.softmax(logits, dim = -1)\n",
        "    # print(softmax.shape)\n",
        "    mask1_word = []\n",
        "    # mask2_word = []\n",
        "    for i in range(0, len(mask_index)):\n",
        "      mask1_word.append(logits[i][mask_index[i]])\n",
        "    mask1_word =  torch.stack(mask1_word)\n",
        "\n",
        "    indices1 = torch.tensor(options).to(device)\n",
        "\n",
        "    predicted1 = []\n",
        "    for i in range(len(mask1_word)):\n",
        "      # print(\"mask, \" , mask1_word[i])\n",
        "      x = [mask1_word[i][j] for j in indices1[i]]\n",
        "      x = torch.stack(x)\n",
        "      # print(x.shape)\n",
        "      predicted1.append(x)\n",
        "\n",
        "    predicted1 = torch.stack(predicted1)\n",
        "\n",
        "    predicted = functional.softmax(predicted1)\n",
        "\n",
        "    return predicted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUmDdt77f7em",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "08604913-9d22-4b0d-f151-2c9b1a94c437"
      },
      "source": [
        "for p in model.model.lm_head.parameters():\n",
        "    print(p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b334ec705cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsKoxKWF41nY"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "bertmodel = AutoModelForMaskedLM.from_pretrained(model_checkpoint, return_dict = True)\n",
        "bertmodel.cuda()\n",
        "\n",
        "model = BertBreak_MC_MLM(bertmodel,tokenizer)\n",
        "model.cuda()\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGB11RJ3qker"
      },
      "source": [
        "params = list(model.named_parameters())\n",
        "# for p in params[0:5]:\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "for p in params:\n",
        "  print(p[-1].grad)\n",
        "  break\n",
        "# params[-1][1].grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhjkzlTx47vp"
      },
      "source": [
        "\n",
        "### learning loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4tgmud83_cT"
      },
      "source": [
        "import random, time\n",
        "import numpy as np\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "criterion = torch.nn.CrossEntropyLoss() \n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "\n",
        "        b_input_ids =batch['input_ids'].to(device)\n",
        "        # print(b_input_ids)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        # # token_type_ids = torch.stack(batch['token_type_ids']).to(device)\n",
        "        b_labels = batch['fixed_label'].to(device)\n",
        "        b_options = batch['options'].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        # print(b_input_ids.shape,b_labels.shape,b_input_mask.shape)\n",
        "        result = model(ids=b_input_ids, \n",
        "                       mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       options = b_options) \n",
        "        \n",
        "        loss = criterion(result, b_labels)\n",
        "        # print(loss)\n",
        "        # loss = result.loss\n",
        "        # logits = result.logits\n",
        "        # print('-----------------loss------------')\n",
        "        # print(loss)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        # print(loss.item())\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        # print(loss.requires_grad)\n",
        "        # loss.requires_grad = True\n",
        "        # loss = Variable(loss, requires_grad = True)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        # raise 1\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    # for p in params[0:5]:\n",
        "    #     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "    # par = list(model.named_parameters())\n",
        "    # params.append(par)\n",
        "    # print(params[-4])\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "    \n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        # print(batch)\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['fixed_label'].to(device)\n",
        "        b_options = batch['options'].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(ids=b_input_ids, \n",
        "                       mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       options = b_options)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = criterion(result, b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = result.detach().cpu().numpy()\n",
        "        label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5VH1uhy3Qcl"
      },
      "source": [
        "if params[0] != params[1]:\n",
        "  print('1')\n",
        "if params[0] != params[2]:\n",
        "  print('2')\n",
        "if params[0] != params[3]:\n",
        "  print('3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5TBmA3C5LAw"
      },
      "source": [
        "### evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Ft8c9F5JjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c91400-e50e-40d3-9b65-c101c5c71f32"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "\n",
        "    b_input_ids = batch['input_ids'].to(device)\n",
        "    b_input_mask = batch['attention_mask'].to(device)\n",
        "    b_labels = batch['fixed_label'].to(device)\n",
        "    b_options = batch['options'].to(device)\n",
        "    with torch.no_grad():\n",
        "      result = model(ids=b_input_ids, \n",
        "                    mask=b_input_mask, \n",
        "                    labels=b_labels,\n",
        "                     options = b_options)\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = result.detach().cpu().numpy()\n",
        "    label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy on test set: {0:.4f}\".format(avg_val_accuracy))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy on test set: 0.2743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VqfyxzISOfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfdca9ad-5417-4aa2-e6f2-476619bf415a"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvApwdRTU-nj"
      },
      "source": [
        "# TODO\n",
        "\n",
        "\n",
        "*   pass tokenizer to fix label (it uses it)\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2s0Ejz1aY9M"
      },
      "source": [
        "# Notes\n",
        "## Run Results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZcKW2XFkrqb"
      },
      "source": [
        "# roberta - break\n",
        "curve_info = 64: 0.23133680555555555,\n",
        " 128: 0.2387152777777778,\n",
        " 256: 0.28515625,\n",
        " 512: 0.38237847222222227,\n",
        " 1024: 0.4735243055555556,\n",
        " 2048: 0.4735243055555556,\n",
        " 4096: 0.4735243055555556}\n",
        " nolang = {64: 0.2191840277777778,\n",
        " 128: 0.2673611111111111,\n",
        " 256: 0.39409722222222227,\n",
        " 512: 0.48046875,\n",
        " 1024: 0.5264756944444444,\n",
        " 2048: 0.5264756944444444,\n",
        " 4096: 0.5264756944444444}\n",
        "##########################################\n",
        "#  bert - break:\n",
        " nolang = {64: 0.1918402777777778,\n",
        " 128: 0.22005208333333334,\n",
        " 256: 0.4153645833333333,\n",
        " 512: 0.7365451388888888,\n",
        " 1024: 0.9079861111111112,\n",
        " 2048: 1.0,\n",
        " 4096: 1.0}\n",
        "curve = {64: 0.19835069444444445,\n",
        " 128: 0.22743055555555555,\n",
        " 256: 0.3298611111111111,\n",
        " 512: 0.3936631944444444,\n",
        " 1024: 0.4752604166666667,\n",
        " 2048: 0.4752604166666667,\n",
        " 4096: 0.5052604166666667}\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}